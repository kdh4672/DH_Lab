{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.backends import cudnn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from model import *\n",
    "from progressBar import printProgressBar\n",
    "from utils import *\n",
    "\n",
    "from time import time\n",
    "\n",
    "parser = argparse.ArgumentParser() \n",
    "outd = 'Results'#dhdh# GAN result 저장소\n",
    "outf ='Images' \n",
    "outl='Losses' #dhdh# loss\n",
    "outm='Models' #dhdh# model weight 저장소\n",
    "\n",
    "workers=8\n",
    "batchSizes=[16, 16, 16, 16, 8, 8]\n",
    "nch=4\n",
    "BN=True\n",
    "WS=True\n",
    "PN=True\n",
    "\n",
    "n_iter=4\n",
    "lambdaGP=10\n",
    "gamma=1\n",
    "e_drift=0.001\n",
    "saveimages=1\n",
    "savenum=64\n",
    "savemodel=10\n",
    "savemaxsize= True\n",
    "# opt = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 0: syntax error near unexpected token `('\r\n",
      "/bin/bash: -c: line 0: `opt = parser.parse_args()'\r\n"
     ]
    }
   ],
   "source": [
    "!opt = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "MAX_RES = 5 ## for 128x128 output (2^2 * 2^MAX_RES) 이므로\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(root='/home/capstone_ai1/kong/403_High_Small/',\n",
    "                                        transform=transform,\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(outd):\n",
    "    os.makedirs(outd)    \n",
    "for f in [outf, outl, outm]:\n",
    "    if not os.path.exists(os.path.join(outd, f)):\n",
    "        os.makedirs(os.path.join(outd, f))       ## 저장소 생성 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(max_res=MAX_RES, nch=nch, nc=3, bn=BN, ws=WS, pn=PN).to(DEVICE)\n",
    "D = Discriminator(max_res=MAX_RES, nch=nch, nc=3, bn=BN, ws=WS).to(DEVICE)\n",
    "\n",
    "#dhdh# Generator, Discriminator 생성\n",
    "\n",
    "#dhdh# max_res : 최종 생성이미지 크기\n",
    "#dhdh# nch : latent space feature map 크기 = nch *32 ex) nch가 16이면 f_m 크기=512\n",
    "#dhdh# nc : input channel\n",
    "#dhdh# bn : if True, BatchNormalization 실행\n",
    "#dhdh# ws : if True, Weight Scaling 실행 : parameter weight들이 동일한 dynamic range를 갖도록 해줌.\n",
    "#dhdh# pn : pixel normalization (generator에만 쓰임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not WS:\n",
    "    # weights are initialized by WScale layers to normal if WS is used\n",
    "    G.apply(weights_init)\n",
    "    D.apply(weights_init)\n",
    "Gs = copy.deepcopy(G) #dhdh# save test용으로 복사\n",
    "optimizerG = Adam(G.parameters(), lr=1e-3, betas=(0, 0.99))\n",
    "optimizerD = Adam(D.parameters(), lr=1e-3, betas=(0, 0.99))\n",
    "\n",
    "GP = GradientPenalty(batchSizes[0], lambdaGP, gamma, device=DEVICE)\n",
    "#dhdh# GradientPenalty\n",
    "# Computes the gradient penalty as defined in \"Improved Training of Wasserstein GANs\n",
    "# (https://arxiv.org/abs/1704.00028)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "global_step = 0\n",
    "total = 2\n",
    "d_losses = np.array([])\n",
    "d_losses_W = np.array([])\n",
    "g_losses = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = Progress(n_iter, MAX_RES, batchSizes)\n",
    "##dhdh## n_iter (int): the number of epochs before changing the progress,\n",
    "##dhdh## pmax (int): the maximum progress of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##dhdh## Progress Class 분석\n",
    "\n",
    "class Progress:\n",
    "    def __init__(self, n_iter, pmax, batchSizeList):\n",
    "        assert n_iter > 0 and isinstance(n_iter, int), 'n_iter must be int >= 1'\n",
    "        assert pmax >= 0 and isinstance(pmax, int), 'pmax must be int >= 0'\n",
    "        assert isinstance(batchSizeList, list) and \\\n",
    "               all(isinstance(x, int) for x in batchSizeList) and \\\n",
    "               all(x > 0 for x in batchSizeList) and \\\n",
    "               len(batchSizeList) == pmax + 1, \\\n",
    "            'batchSizeList must be a list of int > 0 and of length pmax+1'\n",
    "        ##dhdh## 위 규칙을 안 지킬 시 오류 발생\n",
    "        self.n_iter = n_iter\n",
    "        self.pmax = pmax\n",
    "        self.p = 0\n",
    "        self.batchSizeList = batchSizeList\n",
    "\n",
    "    def progress(self, epoch, i, total):\n",
    "        \"\"\"Update the progress given the epoch and the iteration of the epoch\n",
    "        Args:\n",
    "            epoch (int): batch of images to resize\n",
    "            i (int): iteration in the epoch\n",
    "            total (int): total number of iterations in the epoch\n",
    "        \"\"\"\n",
    "        ##dhdh##\n",
    "        \n",
    "        ## ex) epoch = 8, total = 2000, i =20, n_iter = 4\n",
    "        x = (epoch + i / total) / self.n_iter\n",
    "        ## x = 8.001/4 = 2.000025\n",
    "        self.p = min(max(int(x / 2), x - ceil(x / 2), 0), self.pmax)\n",
    "        ## p = min(max(1 , 0.000025 , 0), pmax = 8 )  -> p = 1\n",
    "        \n",
    "        return self.p\n",
    "\n",
    "    def resize(self, images):\n",
    "        \"\"\"Resize the images  w.r.t the current value of the progress.\n",
    "        Args:\n",
    "            images (Variable or Tensor): batch of images to resize\n",
    "        \"\"\"\n",
    "        ##dhdh##  progress에 맞게 resize\n",
    "        x = int(ceil(self.p))\n",
    "        if x >= self.pmax: \n",
    "            return images\n",
    "        else:\n",
    "            return F.adaptive_avg_pool2d(images, 4 * 2 ** x)\n",
    "\n",
    "    @property\n",
    "    def batchSize(self):\n",
    "        \"\"\"Returns the current batchSize w.r.t the current value of the progress\"\"\"\n",
    "        x = int(ceil(self.p))\n",
    "        return self.batchSizeList[x]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_save = hypersphere(torch.randn(savenum, nch * 32, 1, 1, device=DEVICE))\n",
    "\n",
    "##dhdh## 나중에 GAN 학습결과 이미지를 생성할때 쓰일 latent vectors 생성\n",
    "##shape = 64 * 128 * 1 * 1\n",
    "z_save.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.progress(epoch, 1, total)\n",
    "GP.batchSize = P.batchSize\n",
    "# Creation of DataLoader\n",
    "data_loader = DataLoader(dataset,\n",
    "                         batch_size=P.batchSize,\n",
    "                         shuffle=True,\n",
    "                         num_workers=workers,\n",
    "                         drop_last=True,\n",
    "                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## While True:\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "lossEpochG = []\n",
    "lossEpochD = []\n",
    "lossEpochD_W = []\n",
    "\n",
    "G.train()\n",
    "cudnn.benchmark = True\n",
    "\n",
    "P.progress(epoch, 1, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if P.batchSize != data_loader.batch_size:\n",
    "    # update batch-size in gradient penalty\n",
    "    GP.batchSize = P.batchSize\n",
    "    # modify DataLoader at each change in resolution to vary the batch-size as the resolution increases\n",
    "    data_loader = DataLoader(dataset,\n",
    "                             batch_size=P.batchSize,\n",
    "                             shuffle=True,\n",
    "                             num_workers=workers,\n",
    "                             drop_last=True,\n",
    "                             pin_memory=True)\n",
    "total = len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = enumerate(data_loader)\n",
    "i,(images,_) = next(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.progress(epoch, i + 1, total + 1)\n",
    "if P.batchSize != data_loader.batch_size:\n",
    "    # update batch-size in gradient penalty\n",
    "    GP.batchSize = P.batchSize\n",
    "    # modify DataLoader at each change in resolution to vary the batch-size as the resolution increases\n",
    "    data_loader = DataLoader(dataset,\n",
    "                             batch_size=P.batchSize,\n",
    "                             shuffle=True,\n",
    "                             num_workers=opt.workers,\n",
    "                             drop_last=True,\n",
    "                             pin_memory=True)\n",
    "total = len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = enumerate(data_loader)\n",
    "i,(images,_) = next(images)\n",
    "P.progress(epoch, i + 1, total + 1) ##dhdh# return self.p = 0\n",
    "global_step += 1\n",
    "images = images.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 128, 128])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 4, 4])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = P.resize(images) ##dhdh## self.p 가 0 이기 때문에, shape를 4,4로 resize\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128, 1, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.zero_grad()\n",
    "z = hypersphere(torch.randn(P.batchSize, nch * 32, 1, 1, device=DEVICE))\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    fake_images = G(z, P.p) ##dhdh## 4x4 사이즈 fake_image 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_real = D(images, P.p)\n",
    "D_realm = D_real.mean()\n",
    "D_fake = D(fake_images, P.p)\n",
    "D_fakem = D_fake.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0605, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_realm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute gradient penalty for WGAN-GP as defined in the article\n",
    "gradient_penalty = GP(D, images.data, fake_images.data, P.p)\n",
    "\n",
    "# prevent D_real from drifting too much from 0\n",
    "drift = (D_real ** 2).mean() * e_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loss = D_fakem - D_realm\n",
    "d_loss_W = d_loss + gradient_penalty + drift\n",
    "d_loss_W.backward()\n",
    "optimizerD.step()\n",
    "\n",
    "lossEpochD.append(d_loss.item())\n",
    "lossEpochD_W.append(d_loss_W.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== Train the generator ===============#\n",
    "G.zero_grad()\n",
    "\n",
    "z = hypersphere(torch.randn(P.batchSize, nch * 32, 1, 1, device=DEVICE))\n",
    "fake_images = G(z, P.p)\n",
    "\n",
    "# compute scores with new fake images\n",
    "G_fake = D(fake_images, P.p)\n",
    "G_fakem = G_fake.mean()\n",
    "# no need to compute D_real as it does not affect G\n",
    "g_loss = -G_fakem\n",
    "# Optimize\n",
    "g_loss.backward()\n",
    "optimizerG.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  0]  d_loss: 0.0109, d_loss_W: 2.632, progress: 0.00, time: 1938.70s                                 \n"
     ]
    }
   ],
   "source": [
    "lossEpochG.append(g_loss.item())\n",
    "# update Gs with exponential moving average\n",
    "exp_mov_avg(Gs, G, alpha=0.999, global_step=global_step)\n",
    "\n",
    "printProgressBar(i + 1, total + 1,\n",
    "                         length=20,\n",
    "                         prefix=f'Epoch {epoch} ',\n",
    "                         suffix=f', d_loss: {d_loss.item():.3f}'\n",
    "                                f', d_loss_W: {d_loss_W.item():.3f}'\n",
    "                                f', GP: {gradient_penalty.item():.3f}'\n",
    "                                f', progress: {P.p:.2f}')\n",
    "printProgressBar(total, total,\n",
    "                     done=f'Epoch [{epoch:>3d}]  d_loss: {np.mean(lossEpochD):.4f}'\n",
    "                          f', d_loss_W: {np.mean(lossEpochD_W):.3f}'\n",
    "                          f', progress: {P.p:.2f}, time: {time() - t0:.2f}s'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_losses = np.append(d_losses, lossEpochD)\n",
    "d_losses_W = np.append(d_losses_W, lossEpochD_W)\n",
    "g_losses = np.append(g_losses, lossEpochG)\n",
    "\n",
    "# np.save(os.path.join(optoutd, opt.outl, 'd_losses.npy'), d_losses)\n",
    "# np.save(os.path.join(opt.outd, opt.outl, 'd_losses_W.npy'), d_losses_W)\n",
    "# np.save(os.path.join(opt.outd, opt.outl, 'g_losses.npy'), g_losses)\n",
    "\n",
    "cudnn.benchmark = False ##dhdh## True로 하면 input tensor를 하드웨어에 맞게 최적화 해줌\n",
    "# 그러나 input tenor의 사이즈가 계속 바뀌면 악영향을 끼침.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
