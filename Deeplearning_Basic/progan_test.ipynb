{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.backends import cudnn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from model import *\n",
    "from progressBar import printProgressBar\n",
    "from utils import *\n",
    "\n",
    "from time import time\n",
    "\n",
    "parser = argparse.ArgumentParser() \n",
    "outd = 'Results'#dhdh# GAN result 저장소\n",
    "outf ='Images' \n",
    "outl='Losses' #dhdh# loss\n",
    "outm='Models' #dhdh# model weight 저장소\n",
    "\n",
    "workers=8\n",
    "batchSizes=[16, 16, 16, 16, 8, 8]\n",
    "nch=4\n",
    "BN=True\n",
    "WS=True\n",
    "PN=True\n",
    "\n",
    "n_iter=4\n",
    "lambdaGP=10\n",
    "gamma=1\n",
    "e_drift=0.001\n",
    "saveimages=1\n",
    "savenum=64\n",
    "savemodel=10\n",
    "savemaxsize= True\n",
    "# opt = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 0: syntax error near unexpected token `('\r\n",
      "/bin/bash: -c: line 0: `opt = parser.parse_args()'\r\n"
     ]
    }
   ],
   "source": [
    "!opt = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "MAX_RES = 5 ## for 128x128 output (2^2 * 2^MAX_RES) 이므로\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(root='/home/capstone_ai1/kong/403_High_Small/',\n",
    "                                        transform=transform,\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(outd):\n",
    "    os.makedirs(outd)    \n",
    "for f in [outf, outl, outm]:\n",
    "    if not os.path.exists(os.path.join(outd, f)):\n",
    "        os.makedirs(os.path.join(outd, f))       ## 저장소 생성 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(max_res=MAX_RES, nch=nch, nc=3, bn=BN, ws=WS, pn=PN).to(DEVICE)\n",
    "D = Discriminator(max_res=MAX_RES, nch=nch, nc=3, bn=BN, ws=WS).to(DEVICE)\n",
    "\n",
    "#dhdh# Generator, Discriminator 생성\n",
    "\n",
    "#dhdh# max_res : 최종 생성이미지 크기\n",
    "#dhdh# nch : latent space feature map 크기 = nch *32 ex) nch가 16이면 f_m 크기=512\n",
    "#dhdh# nc : input channel\n",
    "#dhdh# bn : if True, BatchNormalization 실행\n",
    "#dhdh# ws : if True, Weight Scaling 실행 : parameter weight들이 동일한 dynamic range를 갖도록 해줌.\n",
    "#dhdh# pn : pixel normalization (generator에만 쓰임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not WS:\n",
    "    # weights are initialized by WScale layers to normal if WS is used\n",
    "    G.apply(weights_init)\n",
    "    D.apply(weights_init)\n",
    "Gs = copy.deepcopy(G) #dhdh# save test용으로 복사\n",
    "optimizerG = Adam(G.parameters(), lr=1e-3, betas=(0, 0.99))\n",
    "optimizerD = Adam(D.parameters(), lr=1e-3, betas=(0, 0.99))\n",
    "\n",
    "GP = GradientPenalty(batchSizes[0], lambdaGP, gamma, device=DEVICE)\n",
    "#dhdh# GradientPenalty\n",
    "# Computes the gradient penalty as defined in \"Improved Training of Wasserstein GANs\n",
    "# (https://arxiv.org/abs/1704.00028)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "global_step = 0\n",
    "total = 2\n",
    "d_losses = np.array([])\n",
    "d_losses_W = np.array([])\n",
    "g_losses = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = Progress(n_iter, MAX_RES, batchSizes)\n",
    "##dhdh## n_iter (int): the number of epochs before changing the progress,\n",
    "##dhdh## pmax (int): the maximum progress of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##dhdh## Progress Class 분석\n",
    "\n",
    "class Progress:\n",
    "    def __init__(self, n_iter, pmax, batchSizeList):\n",
    "        assert n_iter > 0 and isinstance(n_iter, int), 'n_iter must be int >= 1'\n",
    "        assert pmax >= 0 and isinstance(pmax, int), 'pmax must be int >= 0'\n",
    "        assert isinstance(batchSizeList, list) and \\\n",
    "               all(isinstance(x, int) for x in batchSizeList) and \\\n",
    "               all(x > 0 for x in batchSizeList) and \\\n",
    "               len(batchSizeList) == pmax + 1, \\\n",
    "            'batchSizeList must be a list of int > 0 and of length pmax+1'\n",
    "        ##dhdh## 위 규칙을 안 지킬 시 오류 발생\n",
    "        self.n_iter = n_iter\n",
    "        self.pmax = pmax\n",
    "        self.p = 0\n",
    "        self.batchSizeList = batchSizeList\n",
    "\n",
    "    def progress(self, epoch, i, total):\n",
    "        \"\"\"Update the progress given the epoch and the iteration of the epoch\n",
    "        Args:\n",
    "            epoch (int): batch of images to resize\n",
    "            i (int): iteration in the epoch\n",
    "            total (int): total number of iterations in the epoch\n",
    "        \"\"\"\n",
    "        ##dhdh##\n",
    "        ## ex) epoch = 8, total = 2000, i =20, n_iter = 4\n",
    "        x = (epoch + i / total) / self.n_iter\n",
    "        ## x = 8.001/4 = 2.000025\n",
    "        self.p = min(max(int(x / 2), x - ceil(x / 2), 0), self.pmax)\n",
    "        ## p = min(max(1 , 0.000025 , 0), pmax = 8 )  -> p = 1\n",
    "        \n",
    "        return self.p\n",
    "\n",
    "    def resize(self, images):\n",
    "        \"\"\"Resize the images  w.r.t the current value of the progress.\n",
    "        Args:\n",
    "            images (Variable or Tensor): batch of images to resize\n",
    "        \"\"\"\n",
    "        ##dhdh##  progress에 맞게 resize\n",
    "        x = int(ceil(self.p))\n",
    "        if x >= self.pmax: \n",
    "            return images\n",
    "        else:\n",
    "            return F.adaptive_avg_pool2d(images, 4 * 2 ** x)\n",
    "\n",
    "    @property\n",
    "    def batchSize(self):\n",
    "        \"\"\"Returns the current batchSize w.r.t the current value of the progress\"\"\"\n",
    "        x = int(ceil(self.p))\n",
    "        return self.batchSizeList[x]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_save = hypersphere(torch.randn(savenum, nch * 32, 1, 1, device=DEVICE))\n",
    "\n",
    "##dhdh## 나중에 GAN 학습결과 이미지를 생성할때 쓰일 latent vectors 생성\n",
    "##shape = 64 * 128 * 1 * 1\n",
    "z_save.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.progress(epoch, 1, total)\n",
    "GP.batchSize = P.batchSize\n",
    "# Creation of DataLoader\n",
    "data_loader = DataLoader(dataset,\n",
    "                         batch_size=P.batchSize,\n",
    "                         shuffle=True,\n",
    "                         num_workers=workers,\n",
    "                         drop_last=True,\n",
    "                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
